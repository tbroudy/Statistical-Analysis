{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d028ef683bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msklm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\statsmodels\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_constant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGLS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWLS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGLSAR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_ls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRecursiveLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\statsmodels\\regression\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myule_walker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m                                           \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                                           cache_writable)\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memplike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melregress\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_ELRegOpts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresettable_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumdiff\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapprox_fprime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msm_exceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mValueWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mHessianInversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.covariance import ShrunkCovariance, LedoitWolf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.read_csv('train.csv')\n",
    "TestData = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting a Different methodology when working with factor analysis.\n",
    "# Since it's dimensional reduction, -- so I don't see a particular need to reduce features.\n",
    "#TrainTarget = TrainData[['SalePrice']]\n",
    "TrainTarget = TrainData['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.drop(['SalePrice'], axis =1, inplace=True) #So long as properly ordered, this will be fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting maximum potential coverage of dummy variables.\n",
    "TrainTest = TrainData.append(TestData) \n",
    "TrainTest.to_csv('TrainTestCheck1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.select_dtypes(include='object').isnull().sum()[TrainTest.select_dtypes(include='object').isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('Alley','Utilities','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',\n",
    "            'BsmtFinType2','Electrical','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond',\n",
    "           'PoolQC','Fence','MiscFeature'):\n",
    "    TrainTest[col]=TrainTest[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.select_dtypes(include='object').isnull().sum()[TrainTest.select_dtypes(include='object').isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('MSZoning','Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional'):\n",
    "    TrainTest[col]=TrainTest[col].fillna(TrainTest[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.select_dtypes(include=['int','float']).isnull().sum()[TrainTest.select_dtypes(include=['int','float']).isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('LotFrontage','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath','GarageCars','GarageArea','GarageYrBlt'):\n",
    "    TrainTest[col]=TrainTest[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonizing coding on 'Quality' metrics. Overall Qual is numeric, while these others are categorical.\n",
    "#Ordinal assignments seem most appropriate for 9 point scales\n",
    "for col in ('ExterQual','HeatingQC','FireplaceQu','GarageQual','KitchenQual','BsmtQual','BsmtCond','GarageCond','PoolQC'):\n",
    "    TrainTest[col][TrainTest[col] == 'Ex'] = 9\n",
    "    TrainTest[col][TrainTest[col] == 'Gd'] = 7\n",
    "    TrainTest[col][TrainTest[col] == 'TA'] = 5\n",
    "    TrainTest[col][TrainTest[col] == 'Fa'] = 3\n",
    "    TrainTest[col][TrainTest[col] == 'Po'] = 1\n",
    "    TrainTest[col][TrainTest[col] == 'NA'] = 0\n",
    "    TrainTest[col][TrainTest[col] == 'None'] = 0\n",
    "    TrainTest[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.to_csv('TrainTestCheck2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest = pd.get_dummies(TrainTest,dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.to_csv('TrainTestCheck3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.select_dtypes(include='object').isnull().sum()[TrainTest.select_dtypes(include='object').isnull().sum()>0]\n",
    "TrainTest.select_dtypes(include=['int','float']).isnull().sum()[TrainTest.select_dtypes(include=['int','float']).isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending PCA Scores --> array must not contain infs or NaNs. Where do they come from?\n",
    "#I think I want to delete any column that is 100% 0.\n",
    "#These appear to be unwelcome remnants of get_dummies -- dummy_na = True. Perhaps set to false, I'll find this step unnecessary. \n",
    "#(TrainTest != 0).any(axis=0) ==True\n",
    "TrainTest = TrainTest.loc[:, (TrainTest != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got array must not contain infs or NaNs and then LinAlgError: SVD did not converge errors. \n",
    "#Here's a script to get rid of infs and nans.\n",
    "TrainTest = TrainTest.replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\n",
    "\n",
    "TrainTest.to_csv('TrainTestCheck4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest.isnull().values.any()  #No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A problem with running factor analysis - - \n",
    "#Standard methods of performing factor analysis ( i.e., those based on a matrix of Pearsonâ€™s correlations) \n",
    "#assume that the variables are continuous and follow a multivariate normal distribution\n",
    "\n",
    "#What do I do, then? \n",
    "#Tetrachoric correlations as the underlying logic for the factor analysis appear to be the path forward.\n",
    "#But I'll need to figure out what python module will allow this.\n",
    "#I may end up trying PCA instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factor Analysis and PCA require scaling.\n",
    "sc=RobustScaler()\n",
    "TrainTest=sc.fit_transform(TrainTest.values)\n",
    "\n",
    "TrainTest = pd.DataFrame(TrainTest)\n",
    "TrainTest.to_csv('TrainTestCheck5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#transformer = FactorAnalysis(n_components=7, random_state=0)\n",
    "#TrainTest_transformed = transformer.fit_transform(TrainTest)\n",
    "#TrainTest_transformed.shape\n",
    "\n",
    "#Pulling the PCA/Factor Analysis Code straight from Scikit's Example\n",
    "#https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py\n",
    "n_features = len(TrainTest.columns)-1\n",
    "n_components = np.arange(0, n_features, 5)  # options for n_components\n",
    "\n",
    "\n",
    "def shrunk_cov_score(X):\n",
    "    shrinkages = np.logspace(-2, 0, 30)\n",
    "    cv = GridSearchCV(ShrunkCovariance(), {'shrinkage': shrinkages}, cv=5)\n",
    "    return np.mean(cross_val_score(cv.fit(X).best_estimator_, X, cv=5))\n",
    "\n",
    "\n",
    "def compute_scores(X):\n",
    "    pca = PCA(svd_solver='full')\n",
    "    fa = FactorAnalysis()\n",
    "\n",
    "    pca_scores, fa_scores = [], []\n",
    "    for n in n_components:\n",
    "        pca.n_components = n\n",
    "        fa.n_components = n\n",
    "        pca_scores.append(np.mean(cross_val_score(pca, X, cv=5)))\n",
    "        fa_scores.append(np.mean(cross_val_score(fa, X, cv=5)))\n",
    "\n",
    "    return pca_scores, fa_scores\n",
    "\n",
    "\n",
    "def compute_scoresfa(X):\n",
    "    \n",
    "    fa = FactorAnalysis()\n",
    "    fa_scores = []\n",
    "    for n in n_components:\n",
    "        fa.n_components = n\n",
    "        fa_scores.append(np.mean(cross_val_score(fa, X, cv=5)))\n",
    "\n",
    "    return fa_scores\n",
    "\n",
    "def lw_score(X):\n",
    "    return np.mean(cross_val_score(LedoitWolf(), X, cv=5))\n",
    "\n",
    "\n",
    "pca_scores, fa_scores = compute_scores(TrainTest)\n",
    "n_components_pca = n_components[np.argmax(pca_scores)]\n",
    "#n_components_fa = n_components[np.argmax(fa_scores)]\n",
    "#fa_scores = compute_scoresfa(TrainTest)\n",
    "#n_components_fa = n_components[np.argmax(fa_scores)]\n",
    "\n",
    "pca = PCA(svd_solver='full', n_components='mle')\n",
    "pca.fit_transform(TrainTest)\n",
    "#n_components_pca_mle = pca.n_components_\n",
    "\n",
    "#print(\"best n_components by PCA CV = %d\" % n_components_pca)\n",
    "#print(\"best n_components by FactorAnalysis CV = %d\" % n_components_fa)\n",
    "#print(\"best n_components by PCA MLE = %d\" % n_components_pca_mle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I\"m having trouble with Scikit, I'm thinking I might take a look at the statsmodels implementation of PCA.\n",
    "#Recall with PCA -- that when we deploy, we're predicting with the PCA model's components: the combo features that it spits out\n",
    "#Like factor analysis -- it's a set of predictors that replace the original columns.\n",
    "\n",
    "from statsmodels.multivariate.pca import PCA\n",
    "pca_model = PCA(TrainTest, standardize=False, demean=True)\n",
    "fig = pca_model.plot_scree(log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAFac = pd.DataFrame(pca_model.factors)\n",
    "PCAFac.to_csv('smPCAFac.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "lines = ax.plot(pd.DataFrame(pca_model.factors).iloc[:,:10], lw=4, alpha=.6)\n",
    "ax.set_xticklabels(TrainTest.columns.values[::10])\n",
    "ax.set_xlim(0, 51)\n",
    "fig.subplots_adjust(.1, .1, .85, .9)\n",
    "legend = fig.legend(lines, ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6'], loc='center right')\n",
    "legend.draw_frame(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = TrainTest.iloc[:1460]\n",
    "Test = TrainTest.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(TrainData['TotRmsAbvGrd']);\n",
    "#sns.distplot(TrainData['1stFlrSF']);\n",
    "#sns.distplot(TrainData['OverallQual']);\n",
    "#sns.distplot(TrainData['FullBath']);\n",
    "#sns.distplot(TrainData['YearRemodAdd']);\n",
    "#sns.distplot(TrainData['YearBuilt']);\n",
    "#sns.distplot(TrainData['ExterQual']);\n",
    "#sns.distplot(TrainData['LotFrontage']);\n",
    "sns.distplot(np.log(TrainTarget));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.to_csv('Traincheck.csv')\n",
    "Test.to_csv('TestCheck.csv')\n",
    "y=TrainTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.log(y)\n",
    "#Test = Test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Up a Poisson Regression Model -- statsmodels.genmod.families.family.Poisson\n",
    "#Concept - dataset is right skewed. A regression that models a right-skewed distribution is worth investigating.\n",
    "PoiReg = sm.GLM(y,Train,data=Train, family=sm.families.Poisson()).fit()\n",
    "\n",
    "#mod1 = smf.glm(formula=formula, data=dta, family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.iloc[:,1:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.iloc[:,1:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print PoiReg.summary()\n",
    "Result = pd.DataFrame(PoiReg.predict(Test))\n",
    "Result = np.exp(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv('resultreg14.csv')\n",
    "#Output = pd.DataFrame({'Id':TestData[['Id']], 'SalePrice':Result})\n",
    "#Output.to_csv('submissiontmb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
